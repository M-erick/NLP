{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CCS/00081/019 SHALLON SAID\n",
    "##### CCS/00009/019 ERICK MURIITHI\n",
    "##### CCS/00190/019 TECLA BIWOTT\n",
    "### Text Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\murii\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text preprocessing steps achieved:Tokenization,Lowercasing,stopword removal and removing special characters and numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv('movie_reviews.csv')\n",
    "\n",
    "# Remove any non-alphanumeric characters and convert to lowercase\n",
    "df['review'] = df['review'].apply(lambda x: re.sub(r'[^a-zA-Z0-9\\s]', '', x.lower()))\n",
    "\n",
    "# Tokenize the reviews\n",
    "df['review'] = df['review'].apply(lambda x: nltk.word_tokenize(x))\n",
    "\n",
    "# Remove stop words from the reviews\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['review'] = df['review'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "\n",
    "# Stem the words in the reviews\n",
    "ps = PorterStemmer()\n",
    "df['review'] = df['review'].apply(lambda x: [ps.stem(word) for word in x])\n",
    "\n",
    "# Join the words back into sentences\n",
    "df['review'] = df['review'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Save the preprocessed data back to the CSV file\n",
    "df.to_csv('preprocessed_movie_reviews.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Vectorize your texts with one of the document representation echniques discussed in class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessed data into a pandas DataFrame\n",
    "df = pd.read_csv('preprocessed_movie_reviews.csv')\n",
    "\n",
    "# Create a CountVectorizer object\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit the vectorizer to the preprocessed reviews\n",
    "vectorizer.fit(df['review'])\n",
    "\n",
    "# Transform the preprocessed reviews into a bag-of-words matrix\n",
    "bow_matrix = vectorizer.transform(df['review'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train and test a classification model using the corpus you have created:Implemented a Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the preprocessed data and bag-of-words matrix into a pandas DataFrame\n",
    "df = pd.read_csv('preprocessed_movie_reviews.csv')\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(bow_matrix, df['sentiment'], test_size=0.2)\n",
    "\n",
    "# Create a decision tree classifier object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use precision, recall and f-score to measure your model performance \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 score: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Test the classifier on the testing data\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision = precision_score(y_test, y_pred, average='weighted',zero_division=1)\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
